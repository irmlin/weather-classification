{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import sys\r\n",
        "!{sys.executable} -m pip install opendatasets"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting opendatasets\n  Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\nRequirement already satisfied: click in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from opendatasets) (8.1.3)\nCollecting kaggle\n  Downloading kaggle-1.5.12.tar.gz (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n\u001b[?25hRequirement already satisfied: tqdm in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from opendatasets) (4.64.0)\nRequirement already satisfied: six>=1.10 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from kaggle->opendatasets) (1.16.0)\nRequirement already satisfied: certifi in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from kaggle->opendatasets) (2022.6.15)\nRequirement already satisfied: python-dateutil in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from kaggle->opendatasets) (2.8.2)\nRequirement already satisfied: requests in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from kaggle->opendatasets) (2.28.1)\nCollecting python-slugify\n  Downloading python_slugify-6.1.2-py2.py3-none-any.whl (9.4 kB)\nRequirement already satisfied: urllib3 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from kaggle->opendatasets) (1.26.11)\nCollecting text-unidecode>=1.3\n  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.2/78.2 kB\u001b[0m \u001b[31m173.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests->kaggle->opendatasets) (2.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py38_PT_TF/lib/python3.8/site-packages (from requests->kaggle->opendatasets) (3.3)\nBuilding wheels for collected packages: kaggle\n  Building wheel for kaggle (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73049 sha256=02cee6d2401ced56502f05eea96f4f8eb577208998cfb759c576546697f47c56\n  Stored in directory: /home/azureuser/.cache/pip/wheels/29/da/11/144cc25aebdaeb4931b231e25fd34b394e6a5725cbb2f50106\nSuccessfully built kaggle\nInstalling collected packages: text-unidecode, python-slugify, kaggle, opendatasets\nSuccessfully installed kaggle-1.5.12 opendatasets-0.1.22 python-slugify-6.1.2 text-unidecode-1.3\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1668512974166
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "\n",
        "od.download(\"https://www.kaggle.com/datasets/jehanbhathena/weather-dataset\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|██████████| 587M/587M [00:10<00:00, 61.0MB/s] \n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1668515937464
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "od.download(\"https://www.kaggle.com/datasets/pratik2901/multiclass-weather-dataset\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\nYour Kaggle username:Your Kaggle Key:Downloading multiclass-weather-dataset.zip to ./multiclass-weather-dataset\n\n"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "100%|██████████| 91.4M/91.4M [00:02<00:00, 38.6MB/s]\n100%|██████████| 91.4M/91.4M [00:02<00:00, 34.6MB/s]"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1668516474691
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "data_dir_path = os.path.join(os.getcwd(), 'weather-dataset')\n",
        "first_dataset_dir_path = os.path.join(data_dir_path, 'dataset')\n",
        "first_dataset_dirs = os.listdir(first_dataset_dir_path)\n",
        "\n",
        "for dir_name in first_dataset_dirs:\n",
        "  shutil.move(os.path.join(first_dataset_dir_path, dir_name), data_dir_path)\n",
        "os.rmdir(first_dataset_dir_path)"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1668516492037
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "second_dataset_dir_path = os.path.join(os.getcwd(), 'multiclass-weather-dataset', 'Multi-class Weather Dataset')\n",
        "\n",
        "second_rain_dir = os.path.join(second_dataset_dir_path, 'Rain')\n",
        "second_rain_dir_renamed = os.path.join(second_dataset_dir_path, 'rain1')\n",
        "os.rename(second_rain_dir, second_rain_dir_renamed)\n",
        "\n",
        "second_dataset_dirs = os.listdir(second_dataset_dir_path)\n",
        "\n",
        "\n",
        "for dir_name in second_dataset_dirs:\n",
        "  shutil.move(os.path.join(second_dataset_dir_path, dir_name), data_dir_path)\n",
        "shutil.rmtree(os.path.join(os.getcwd(), 'multiclass-weather-dataset'))"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1668516494715
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_rain_dir = os.path.join(data_dir_path, 'rain')\n",
        "second_rain_dir = os.path.join(data_dir_path, 'rain1')\n",
        "second_rain_dir_images = os.listdir(second_rain_dir)\n",
        "\n",
        "for image_file in second_rain_dir_images:\n",
        "  shutil.move(os.path.join(second_rain_dir, image_file), first_rain_dir)\n",
        "os.rmdir(second_rain_dir)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1668516512961
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for class_name in os.listdir(data_dir_path):\n",
        "\n",
        "  current_dir_path = os.path.join(data_dir_path, class_name)  \n",
        "\n",
        "  # skip hidden folders\n",
        "  if class_name.startswith('.'):\n",
        "    continue\n",
        "\n",
        "  if class_name[0].isupper():\n",
        "    new_dir_path = os.path.join(data_dir_path, class_name.lower())\n",
        "    os.rename(current_dir_path, new_dir_path)\n",
        "    current_dir_path = new_dir_path\n",
        "\n",
        "  for index, image_file_name in enumerate(os.listdir(current_dir_path)):\n",
        "    extension = image_file_name.split('.')[-1]\n",
        "    new_image_file_name = ''.join([str(index), '.', extension])\n",
        "    try:\n",
        "      os.rename(\n",
        "        os.path.join(current_dir_path, image_file_name),\n",
        "        os.path.join(current_dir_path, new_image_file_name)\n",
        "      )\n",
        "    except FileExistsError:\n",
        "      continue\n"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1668516940683
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml-pt-tf",
      "language": "python",
      "display_name": "Python 3.8 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "3d08b197395ff9c13d611a82f8666597c7b4f03b34ef71765c8d241627dec079"
      }
    },
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}